{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T05:30:25.419014Z",
     "start_time": "2020-12-21T05:30:23.124472Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "tf.config.optimizer.set_jit(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T05:32:57.062942Z",
     "start_time": "2020-12-21T05:32:19.862367Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0~887 is only for 2017/10 ~2018/12/31 data use\n",
    "\n",
    "\n",
    "AIR_Train = np.load('AIR_DomainB_Training.npy')[:887]\n",
    "AIR_Test = np.load('AIR_DomainB_Testing.npy')\n",
    "\n",
    "SAT_Train = np.load('SAT_DomainB_Training.npy')[:887]\n",
    "SAT_Test = np.load('SAT_DomainB_Testing.npy')\n",
    "\n",
    "# EPA_Train = np.load('EPA_DomainB_Training.npy')\n",
    "# EPA_Test = np.load('EPA_DomainB_Testing.npy')\n",
    "\n",
    "train = np.concatenate([AIR_Train,SAT_Train])\n",
    "test = np.concatenate([AIR_Test,SAT_Test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T05:33:32.247061Z",
     "start_time": "2020-12-21T05:33:32.230490Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def glob_all(dir_path):\n",
    "    file_list = glob.glob(os.path.join(dir_path,'*.h5'))\n",
    "    inside = os.listdir(dir_path)\n",
    "    for dir_name in inside:\n",
    "        if os.path.isdir(os.path.join(dir_path,dir_name)):\n",
    "            file_list.extend(glob_all(os.path.join(dir_path,dir_name)))\n",
    "    return file_list\n",
    "\n",
    "def auto_delete_hdf5_save_history(history,path):\n",
    "    file_list = glob_all(path)\n",
    "    for i in range(len(file_list)-1):\n",
    "        file_list.sort()\n",
    "        if (len(file_list)-1) == 0:\n",
    "            print('Only had Best Weight , Cound not delete !')\n",
    "        else:\n",
    "            os.remove(file_list[i])\n",
    "            \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(path+'plt-loss.png')\n",
    "    plt.clf()\n",
    "\n",
    "def Encoder(channel_number):\n",
    "    input_img = Input(shape=(348,204,1))\n",
    "    e1 = Conv2D(16, (3, 3), activation='tanh', padding='same')(input_img)\n",
    "    e2 = MaxPooling2D((2, 2), padding='same')(e1)\n",
    "    e3 = Conv2D(8, (3, 3), activation='tanh', padding='same')(e2)\n",
    "    e4 = MaxPooling2D((2, 2), padding='same')(e3)\n",
    "    e5 = Conv2D(channel_number, (3, 3), activation='tanh', padding='same')(e4)\n",
    "    e6 = MaxPooling2D((2, 2), padding='same')(e5)\n",
    "    e7 = Activation('tanh')(e6)\n",
    "    return Model(input_img, e7)\n",
    "\n",
    "def Decoder(channel_number):\n",
    "    input_img = Input(shape=(44,26,channel_number))\n",
    "    d1 = Conv2D(8, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    d2 = UpSampling2D((2, 2))(d1)\n",
    "    d3 = Conv2D(16, (3, 3), activation='relu', padding='same')(d2)\n",
    "    d4 = UpSampling2D((2, 2))(d3)\n",
    "    d5 = Conv2D(32, (3, 3), activation='relu')(d4)\n",
    "    d6 = UpSampling2D((2, 2))(d5)\n",
    "    d7 = Conv2D(1, (3, 3), activation='relu', padding='same')(d6)\n",
    "    return Model(input_img, d7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T07:34:30.210072Z",
     "start_time": "2020-12-21T05:33:47.742302Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "channel_number = 6; total_training_time = 30\n",
    "\n",
    "for training_time in range(total_training_time):\n",
    "    \n",
    "    path = 'Weight/1718AIRSAT_channel'+str(channel_number)+'/'+str(training_time)+'/'\n",
    "    if not os.path.exists(path):os.makedirs(path)\n",
    "    K.clear_session()\n",
    "    x = Input(shape=(348, 204, 1))\n",
    "\n",
    "    Encoder_model = Encoder(channel_number)\n",
    "    Decoder_model = Decoder(channel_number)\n",
    "\n",
    "    Autoencoder = Model(x,Decoder_model(Encoder_model(x)))\n",
    "    Autoencoder.compile(loss='mse',optimizer='Adam')\n",
    "\n",
    "    filepath=path+'/{epoch:04d}-train_{loss:f}-test_{val_loss:f}.h5'\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=50, verbose=1, min_delta=0.01)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor = 0.2, patience=15, min_lr = 2e-7, verbose = 1)                   \n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, mode='auto')\n",
    "    callbacks_list = [earlystopper, reduce_lr, checkpoint]\n",
    "\n",
    "    history = Autoencoder.fit(train,train, validation_data=(test,test), batch_size=16, \n",
    "                              epochs=2000,verbose=1,callbacks=callbacks_list)\n",
    "    auto_delete_hdf5_save_history(history,path)\n",
    "    del Encoder_model\n",
    "    del Decoder_model\n",
    "    del Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T07:35:41.223722Z",
     "start_time": "2020-12-21T07:35:26.330443Z"
    }
   },
   "outputs": [],
   "source": [
    "train = np.concatenate([AIR_Train,SAT_Train])\n",
    "\n",
    "channel_number = 6\n",
    "x = Input(shape=(348, 204, 1))\n",
    "\n",
    "Encoder_model = Encoder(channel_number)\n",
    "Decoder_model = Decoder(channel_number)\n",
    "\n",
    "Autoencoder = Model(x,Decoder_model(Encoder_model(x)))\n",
    "Autoencoder.load_weights(glob_all('Weight/1718AIRSAT_channel'+str(channel_number))[0])\n",
    "pred = Encoder_model.predict(train)\n",
    "np.save('1718AIRSAT_DomainB_Code_Training',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T16:54:10.281291Z",
     "start_time": "2020-12-06T16:53:39.848651Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.concatenate([AIR_Train,SAT_Train])\n",
    "\n",
    "channel_number = 6\n",
    "x = Input(shape=(348, 204, 1))\n",
    "\n",
    "Encoder_model = Encoder(channel_number)\n",
    "Decoder_model = Decoder(channel_number)\n",
    "\n",
    "Autoencoder = Model(x,Decoder_model(Encoder_model(x)))\n",
    "Autoencoder.load_weights(glob_all('Weight/AIRSAT_channel'+str(channel_number))[0])\n",
    "pred = Encoder_model.predict(train)\n",
    "np.save('AIRSAT_DomainB_Code_Training',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T16:56:16.855748Z",
     "start_time": "2020-12-06T16:55:35.128071Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.concatenate([AIR_Train,SAT_Train,EPA_Train])\n",
    "\n",
    "channel_number = 6\n",
    "x = Input(shape=(348, 204, 1))\n",
    "\n",
    "Encoder_model = Encoder(channel_number)\n",
    "Decoder_model = Decoder(channel_number)\n",
    "\n",
    "Autoencoder = Model(x,Decoder_model(Encoder_model(x)))\n",
    "Autoencoder.load_weights(glob_all('Weight/AIRSATEPA_channel'+str(channel_number))[0])\n",
    "pred = Encoder_model.predict(train)\n",
    "np.save('AIRSATEPA_DomainB_Code_Training',pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
